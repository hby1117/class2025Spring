{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hby1117/class2025Spring/blob/main/06_NLP_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63GYOqR85wYd"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dDlyezhLJPs"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBte5zZZ6F3d"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "text = \"The quick, brown foxes are jumping over the lazy dogs.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uinUm4cJ6Jr-"
      },
      "outputs": [],
      "source": [
        "# Punkt tokenizer\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "words = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdpr5fv4KPeT"
      },
      "outputs": [],
      "source": [
        "# Regular expression tokenizer\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7bf40zfLQMd"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18zpaJgPLWP0"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhR_rRoXLPbx"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "norm_words = [stemmer.stem(w) for w in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfWyxs5ILyOP"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "stemmer = LancasterStemmer()\n",
        "norm_words = [stemmer.stem(w) for w in words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plUUAsIBMG-C"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em-ZlDwgMKpN"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "norm_words = [lemmatizer.lemmatize(w) for w in words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e1BkTDwOGMQ"
      },
      "source": [
        "## Part-of-speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vihwU8ehOS6_"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "pos = nltk.pos_tag(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq-Nxb0NOjci"
      },
      "outputs": [],
      "source": [
        "norm_words = []\n",
        "\n",
        "for word, tag in pos:\n",
        "  t = tag[0].lower()\n",
        "  if t in [\"n\", \"v\"]:\n",
        "    norm_words.append(lemmatizer.lemmatize(word, t))\n",
        "    print(f\"{word}: {t}\")\n",
        "  else:\n",
        "    norm_words.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NfDm1pRTTA-"
      },
      "source": [
        "## Stopword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJQoK_GbTVj-"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "new_words = []\n",
        "for word in words:\n",
        "  if not word in stopwords.words(\"english\"):\n",
        "    new_words.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A58NJZNXTzMk"
      },
      "source": [
        "## Collocation & Concordance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnbtkNwJUiIS"
      },
      "source": [
        "### Collocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-s542NsUlMk"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"gutenberg\")\n",
        "\n",
        "text = nltk.corpus.gutenberg.raw(\"carroll-alice.txt\")\n",
        "words = retokenize.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBie_z0cVEwD"
      },
      "outputs": [],
      "source": [
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(words[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5thm5_6_VdjP"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).collocations()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owd-UAYyUiPH"
      },
      "source": [
        "### Concordance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcjoDgKeVoZI"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).concordance(\"Alice\", 79, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWWRDF4JEErP"
      },
      "source": [
        "### Dispersion Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KipVkjPNW5GP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "characters = [\"Alice\", \"Rabbit\", \"Cat\", \"Hatter\", \"Queen\"]\n",
        "ax = nltk.draw.dispersion_plot(words, characters, ignore_case=True)\n",
        "ax.set_yticks(list(range(len(characters))), reversed(characters))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfiBUvscOEcd"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).similar(\"Alice\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ16axPZOtT3"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).common_contexts([\"Alice\", \"she\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RshuDGt3QIe4"
      },
      "source": [
        "## Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oniam7uwSSq_"
      },
      "outputs": [],
      "source": [
        "text = nltk.corpus.gutenberg.raw(\"shakespeare-hamlet.txt\")\n",
        "words = retokenize.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10M6dmcRQM80"
      },
      "outputs": [],
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw-MxlVkQcNj"
      },
      "outputs": [],
      "source": [
        "words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "fd = nltk.FreqDist(words).most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgwZGsD5Uoyk"
      },
      "outputs": [],
      "source": [
        "nltk.Text(words).plot(20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76aUeVQcU2Zl"
      },
      "source": [
        "## Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSBBuktZUycB"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "wct = WordCloud()\n",
        "\n",
        "wc = wct.generate(text)\n",
        "plt.imshow(wc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E60bWHf_Veqp"
      },
      "outputs": [],
      "source": [
        "text = nltk.corpus.gutenberg.raw(\"bible-kjv.txt\")\n",
        "\n",
        "wc = wct.generate(text)\n",
        "plt.imshow(wc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO5o7SjNUgn3iiv/pq/Ufc2",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
