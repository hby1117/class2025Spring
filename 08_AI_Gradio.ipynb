{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hby1117/class2025Spring/blob/main/08_AI_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWzWCwYppGU5"
      },
      "source": [
        "# Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "!pip install SpeechRecognition\n",
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMXj5bktpR3N"
      },
      "source": [
        "## Simple Calculator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def add(first_num, second_num):\n",
        "  result = first_num + second_num\n",
        "  return f\"Answer is: {result}\"\n",
        "\n",
        "interface = gr.Interface(fn=add, inputs = [\"number\", \"number\"], outputs=\"text\")\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_h-8IHC0Ie_"
      },
      "source": [
        "## Speech-to-Text (STT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def stt(audio_file):\n",
        "    stt_model = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_recorded = stt_model.record(source)\n",
        "        text = stt_model.recognize_google(audio_recorded)\n",
        "    return text\n",
        "\n",
        "interface = gr.Interface(fn=stt, inputs=\"file\", outputs=\"text\")\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuCGVeIw07pO"
      },
      "source": [
        "## Text-to-Speech (TTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def tts(text):\n",
        "  tts_model = gTTS(text)\n",
        "  tts_model.save(\"tts_output.wav\")\n",
        "  return \"tts_output.wav\"\n",
        "\n",
        "interface = gr.Interface(fn=tts, inputs=\"text\", outputs=\"audio\")\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aimmzztm1yt7"
      },
      "source": [
        "## Voice Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "chat_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "def stt(audio_file):\n",
        "    stt_model = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_recorded = stt_model.record(source)\n",
        "        text = stt_model.recognize_google(audio_recorded)\n",
        "    return text\n",
        "\n",
        "def tts(text):\n",
        "  tts_model = gTTS(text)\n",
        "  tts_model.save(\"tts_output.wav\")\n",
        "  return \"tts_output.wav\"\n",
        "\n",
        "# No chat history\n",
        "def chatbot(text):\n",
        "  input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors=\"pt\")\n",
        "  output_ids = chat_model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "  output = tokenizer.decode(output_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "  return output\n",
        "\n",
        "def voice_chatbot(audio):\n",
        "  user_text = stt(audio)\n",
        "  chatbot_text = chatbot(user_text)\n",
        "  speech_file = tts(chatbot_text)\n",
        "  return user_text, chatbot_text, speech_file\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=voice_chatbot,\n",
        "    inputs=\"file\",\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"User Text\"),\n",
        "        gr.Textbox(label=\"Chatbot Response\"),\n",
        "        gr.Audio(label=\"Chatbot Audio\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMzYg+8IziNauJARd1YRtoi",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
